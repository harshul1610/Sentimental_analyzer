{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = imdb.load_data()\n",
    "x = np.concatenate((x_train, x_test),axis=0)\n",
    "y = np.concatenate((y_train,y_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print np.shape(x_train)\n",
    "print type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique classes:  [0 1]\n",
      "Number of unique words:  88585\n"
     ]
    }
   ],
   "source": [
    "print 'Number of Unique classes: ', np.unique(y)\n",
    "print 'Number of unique words: ', len(np.unique(np.hstack(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 234.76 words (172.911495)\n"
     ]
    }
   ],
   "source": [
    "print 'Review length: '\n",
    "result = [len(i) for i in x]\n",
    "print(\"Mean %.2f words (%f)\" % (np.mean(result), np.std(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQCSVFIGgCSV1P8HWNYGmuh8LE0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1658072750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(result)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    1,   14,   22,   16,\n",
       "         43,  530,  973, 1622, 1385,   65,  458, 4468,   66, 3941,    4,\n",
       "        173,   36,  256,    5,   25,  100,   43,  838,  112,   50,  670,\n",
       "          2,    9,   35,  480,  284,    5,  150,    4,  172,  112,  167,\n",
       "          2,  336,  385,   39,    4,  172, 4536, 1111,   17,  546,   38,\n",
       "         13,  447,    4,  192,   50,   16,    6,  147, 2025,   19,   14,\n",
       "         22,    4, 1920, 4613,  469,    4,   22,   71,   87,   12,   16,\n",
       "         43,  530,   38,   76,   15,   13, 1247,    4,   22,   17,  515,\n",
       "         17,   12,   16,  626,   18,    2,    5,   62,  386,   12,    8,\n",
       "        316,    8,  106,    5,    4, 2223,    2,   16,  480,   66, 3785,\n",
       "         33,    4,  130,   12,   16,   38,  619,    5,   25,  124,   51,\n",
       "         36,  135,   48,   25, 1415,   33,    6,   22,   12,  215,   28,\n",
       "         77,   52,    5,   14,  407,   16,   82,    2,    8,    4,  107,\n",
       "        117,    2,   15,  256,    4,    2,    7, 3766,    5,  723,   36,\n",
       "         71,   43,  530,  476,   26,  400,  317,   46,    7,    4,    2,\n",
       "       1029,   13,  104,   88,    4,  381,   15,  297,   98,   32, 2071,\n",
       "         56,   26,  141,    6,  194,    2,   18,    4,  226,   22,   21,\n",
       "        134,  476,   26,  480,    5,  144,   30,    2,   18,   51,   36,\n",
       "         28,  224,   92,   25,  104,    4,  226,   65,   16,   38, 1334,\n",
       "         88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,   15,\n",
       "         16,    2,   19,  178,   32], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test,maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               4000250   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000, 32, input_length=500))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "98s - loss: 0.5350 - acc: 0.6929 - val_loss: 0.3189 - val_acc: 0.8610\n",
      "Epoch 2/2\n",
      "91s - loss: 0.2267 - acc: 0.9112 - val_loss: 0.2871 - val_acc: 0.8808\n",
      "Accuracy: 88.08%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=2, batch_size=128, verbose=2)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               2000250   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,163,605\n",
      "Trainable params: 2,163,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "107s - loss: 0.5971 - acc: 0.6378 - val_loss: 0.3282 - val_acc: 0.8589\n",
      "Epoch 2/2\n",
      "124s - loss: 0.2584 - acc: 0.8973 - val_loss: 0.2733 - val_acc: 0.8854\n",
      "Accuracy: 88.54%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "# pad dataset to a maximum review length in words\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
